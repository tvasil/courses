{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic form\n",
    "\n",
    "`p(A|B) = p(A, B) / p(B)`\n",
    "\n",
    "### Example: buying from your website\n",
    "\n",
    "A = {Buys, Does not Buy}, B = {USA, Canada, Mexico}\n",
    "\n",
    "![buys](img/country_buy.png)\n",
    "\n",
    "Support we want to find p(Buy?| Country)\n",
    "\n",
    "**Marginal Probability**\n",
    "\n",
    "`p(country = Mexico)= 210/(210+550+320) = 0.19\n",
    "p(country = US) = 550/(210+550 + 320) = 0.51\n",
    "p(country = Canada) = 320 / (210 + 550 + 320) = 0.30`\n",
    "\n",
    "**Joint probability**\n",
    "- How many probabilities are we looking for here?\n",
    "    - Buy = 2 possiblities\n",
    "    - Country = 3 possiblities\n",
    "    - Total = 2*3 possiblities\n",
    "- In general, the total = |RV1| * |RV2| * |RV3| * ... * |RVn|\n",
    "    - and this number grows exponentially as we add more variables => **curse of dimensionality**\n",
    "    \n",
    "    \n",
    "`p(buy = 1, country = CA) = 20/1080 = 0.019\n",
    "p(buy = 0, country = CA) = 300/1080 = 0.28\n",
    "p(buy = 1, country = US) = 50/1080 = 0.046\n",
    "p(buy = 0, country = US) = 500/1080 = 0.46\n",
    "p(buy = 1, country = MX) = 10/1080 = 0.0093\n",
    "p(buy = 0, country = MX) = 200/1080 = 0.19`\n",
    "\n",
    "_They all have to sum to 1!!_\n",
    "\n",
    "\n",
    "**!NOTE**\n",
    "\n",
    "As the number of parameters grows, the joint probabilities become tiny and the computer will eventually round down to 0\n",
    "- this is called the **\"underflow\" problem**, which is common in probability\n",
    "- we use log probability instead as it grows slower as its argument increases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conditional Probabilities**\n",
    "\n",
    "`\n",
    "p(buy = 1 | country = CA) = 0.019 / 0.30 = 0.06\n",
    "p(buy = 0 | country = CA) = 0.28 / 0.30 = 0.93\n",
    "p(buy = 1 | country = US) = 0.046 / 0.51 = 0.09\n",
    "p(buy = 0 | country = US) = 0.46 / 0.51 = 0.91\n",
    "p(buy = 1 | country = MX) = 0.009 / 0.19 = 0.05\n",
    "p(buy = 0 | country = MX) = 0.185 / 0.19 = 0.97`\n",
    "\n",
    "\n",
    "_This no longer sums to 1!_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the conditional probability is independent of the random variable that it's conditioned on, then it becomes the **marginal probability**: \n",
    "\n",
    "if A & B are independent, i.e.\n",
    "\n",
    "`p(A, B) = p(A)*p(B)`\n",
    "\n",
    "so, if Buy and Country are independent (let's say if the buying percentage is the same across countries), then:\n",
    "\n",
    "`p(Buy | Country) = p(Buy, Country) / p(Country) \n",
    "                  = p(Buy)*p(Country) / p(Country)\n",
    "                  = p(Buy) `"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Bayes Rule\n",
    "\n",
    "` p(A|B) = p(B | A)* p(A) / p(B)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monty Hall problem\n",
    "\n",
    "[Explanation](https://betterexplained.com/articles/understanding-the-monty-hall-problem/)\n",
    "\n",
    "### Setup\n",
    "- You can choose one of three doors (one has a car, two have a goat)\n",
    "- The host opens another door, which always has a goat\n",
    "- You have the option to switch or to stay with your door. \n",
    "\n",
    "### Explanation\n",
    "The best strategy is to change doors, because once the host has revealed another door that has a goat, the chances that the car is behing the other one are aroun 67%. Why?\n",
    "\n",
    "- Assume we choose always door #1 \n",
    "- C: here the car really is\n",
    "- p(C = 1) = p(C = 2) = p(C = 3) = 1/3\n",
    "- H: door that Monty Hall opens\n",
    "- Assume he opens door # 2 without loss of generality, the problem is symmetric: \n",
    "\n",
    "`p(H = 2 | C = 1) = 0.5` # he has to select one of the other two doors\n",
    "\n",
    "`p(H = 2 | C = 2) = 0` If the car is behind door #2, there is 0 probability Monty Hall would open that door (which is the one he did open)\n",
    "\n",
    "`p(H = 2 | C = 3) = 1` If the car is actually behind door #3, there is 100% chance Monty Hall would open door 2. \n",
    "\n",
    "#### What probability do we want?\n",
    "\n",
    "`p(C = 1|H = 2), p(C = 3| H = 2)`\n",
    "\n",
    "\n",
    "Using Bayes Rule, we calculate that \n",
    "\n",
    "`p(C = 3 | H = 2) = p(H = 2 | C = 3) * p(C = 3) / [p(H = 2 | C = 1) * p (C = 1) + p(H = 2| C = 2) * p (C = 2) + p(H = 2 | C = 3)*p(C = 3)]`\n",
    "\n",
    "==>\n",
    "\n",
    "`p(C = 3 | H = 2) = 1* 1/3 / (1/2 * 1/3 + 0*1/3 + 1*1/3) = 2/3`\n",
    "\n",
    "==>\n",
    "\n",
    "`p(C = 1|H = 2)` = 1/3\n",
    "\n",
    "`p(C = 3|H = 2)` = 2/3\n",
    "\n",
    "Which means that we should always swicth "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian example\n",
    "\n",
    "- Suppose we have collected one data point from a source of Gaussian-distributed data, and let's call it \"x\"\n",
    "- What is the probability density of that one data point?\n",
    "\n",
    "![gaussian_single_point](img/single_datapoint_probability.png)\n",
    "\n",
    "In real life we will collect multiple samples\n",
    "- Typically the samples are IID - independent and identically distributed\n",
    "\n",
    "#### Joint probability density\n",
    "![joint_probability](img/joint_probability.png)\n",
    "This means I can multiply the probaility of each individual sample to get the joint probability of all the samples\n",
    "\n",
    "#### Mean of the Gaussian: Data likelihood\n",
    "\n",
    "We write the \"probability of the data given the parameters\", which is actually what the Bayesians call **likelihood**\n",
    "- The parameters depend on what the model is (e.g. Gaussian, Beta, Gamma, etc)\n",
    "\n",
    "![likelihood](img/likelihood_given_params.png)\n",
    "\n",
    "\n",
    "### Maximum Likelihood\n",
    "\n",
    "\"What is the best setting of mu, such that the likelihood is maximized?\"\n",
    "- To maximize the likelihood function in respect to the variable, we use calculus (set dP/d _mu_ = 0, solve for _mu_)\n",
    "- Taking the log is useful to avoid the **underflow problem** to get rid of the exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Likelihood: Click Through Rate\n",
    "\n",
    "This is different to the Gaussian, it's the Bernoulli distribution\n",
    "\n",
    "\n",
    "### Problem set up \n",
    "- H = Click, T = No click, H + T = total # impressions\n",
    "- Also IID\n",
    "- Let's call p(H) = p, so p(T) = 1 - p\n",
    "- Bernoulli only has 1 parameter (Gaussian has 2)\n",
    "- Suppose we flip 2H, 3T - what is the total likelihood?\n",
    "\n",
    "Likelihood function: `L(N_h, N_t) = p^N_h * (1-p) * N_t`\n",
    "\n",
    "So what is the maximum likelihood estimate of p?\n",
    "\n",
    "log-likelihood gives us the solution: \n",
    "\n",
    "`p = N_h / (N_h + N_t)`, which is basically how often heard appears over the total number of tosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confidence level is the inverse of the significance level\n",
    "- Confidence interval is the range that most likely contains the real population _mu_ ==> we can (almost) say \"_mu_ is probably here\" \n",
    "- What is **don't mean** is \"mu is in the interval with 95% probability\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
